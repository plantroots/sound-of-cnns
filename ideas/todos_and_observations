TODO:

1. raise samplerate
2. modify latent space dims
3. modify the architecture
4. train more (google colab)
5. experiment with more activation/normalization combos
6. use sigma as a hyperparameter (reconstruction_loss_weight)
7. experiment with a LR scheduler (fixed seed and plan it)
8. train on both raw audio and spectrograms
9. post-processing smoothing to fill in the gaps
10. add tensorboard scalars
11. double check the generated sample save to disk methods
12. reconstruction weight between 1-10 normally
13. LS normal dims for audio: 16-256. A common choice would be 64-128.
14. create a de-noising autoencoder
15. visualize latent_space representations of random samples
16. remove zeroes from start and try to reduce the length more (or drag to middle)


OBSERVATIONS:

1. modifying the LS dims actually shapes the waveform
2. modifying the LS dims actually shapes the waveform from 5 to 10, adds more low-end
3. different LR, same loss value issue:
4. increasing the filter size give better and better results -> ex:

    vae = VAE(
        input_shape=(NUM_OF_SAMPLES_IN_A_FILE, 1),
        conv_filters=(512, 256, 128, 64, 32),
        conv_kernels=(1024, 1024, 1024, 1024, 1024),
        conv_strides=(40, 4, 4, 4, 4),
        latent_space_dim=5
    )
